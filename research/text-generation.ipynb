{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directoryz\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-24T09:01:45.271268Z","iopub.execute_input":"2023-08-24T09:01:45.271678Z","iopub.status.idle":"2023-08-24T09:01:45.287900Z","shell.execute_reply.started":"2023-08-24T09:01:45.271638Z","shell.execute_reply":"2023-08-24T09:01:45.286161Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet transformers[torch] gdown datasets","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:08.181732Z","iopub.execute_input":"2023-08-24T09:12:08.182250Z","iopub.status.idle":"2023-08-24T09:12:23.595090Z","shell.execute_reply.started":"2023-08-24T09:12:08.182206Z","shell.execute_reply":"2023-08-24T09:12:23.593614Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# import gdown\n\n# gdown.download(\"https://drive.google.com/uc?id=1DcRYrn_ZJwTdzXPjWNImO-mbHE0yRt8P\", \"data.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:26.961607Z","iopub.execute_input":"2023-08-24T09:12:26.961977Z","iopub.status.idle":"2023-08-24T09:12:26.968708Z","shell.execute_reply.started":"2023-08-24T09:12:26.961943Z","shell.execute_reply":"2023-08-24T09:12:26.967702Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n\n# df = pd.read_csv(\"data.csv\")\n# df = df.drop(['Unnamed: 0'], axis=1)\n# df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.456709Z","iopub.execute_input":"2023-08-24T09:12:27.457082Z","iopub.status.idle":"2023-08-24T09:12:27.461371Z","shell.execute_reply.started":"2023-08-24T09:12:27.457046Z","shell.execute_reply":"2023-08-24T09:12:27.460444Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# df['tags'] = df['tags'].apply(lambda x: x[1:-1].replace(\"'\", ''))","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.487854Z","iopub.execute_input":"2023-08-24T09:12:27.488141Z","iopub.status.idle":"2023-08-24T09:12:27.492351Z","shell.execute_reply.started":"2023-08-24T09:12:27.488115Z","shell.execute_reply":"2023-08-24T09:12:27.491277Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# df['text'] = \"Write an essay on title: \" + df['title'] + \"with tags: \" +df['tags'] + \" \\nArticle Text:  \" + df['text']","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.579521Z","iopub.execute_input":"2023-08-24T09:12:27.579813Z","iopub.status.idle":"2023-08-24T09:12:27.584386Z","shell.execute_reply.started":"2023-08-24T09:12:27.579786Z","shell.execute_reply":"2023-08-24T09:12:27.583370Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# df_sample = df.sample(50000)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.586497Z","iopub.execute_input":"2023-08-24T09:12:27.587237Z","iopub.status.idle":"2023-08-24T09:12:27.595160Z","shell.execute_reply.started":"2023-08-24T09:12:27.587202Z","shell.execute_reply":"2023-08-24T09:12:27.594296Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# df_sample = df_sample.reset_index().drop(['index'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.597155Z","iopub.execute_input":"2023-08-24T09:12:27.597867Z","iopub.status.idle":"2023-08-24T09:12:27.611951Z","shell.execute_reply.started":"2023-08-24T09:12:27.597836Z","shell.execute_reply":"2023-08-24T09:12:27.610916Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# df_sample.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.623391Z","iopub.execute_input":"2023-08-24T09:12:27.625316Z","iopub.status.idle":"2023-08-24T09:12:27.628697Z","shell.execute_reply.started":"2023-08-24T09:12:27.625288Z","shell.execute_reply":"2023-08-24T09:12:27.627780Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# df_sample = df_sample.astype(str)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.647822Z","iopub.execute_input":"2023-08-24T09:12:27.648556Z","iopub.status.idle":"2023-08-24T09:12:27.652439Z","shell.execute_reply.started":"2023-08-24T09:12:27.648525Z","shell.execute_reply":"2023-08-24T09:12:27.651514Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# df_sample.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.688646Z","iopub.execute_input":"2023-08-24T09:12:27.690239Z","iopub.status.idle":"2023-08-24T09:12:27.694521Z","shell.execute_reply.started":"2023-08-24T09:12:27.690207Z","shell.execute_reply":"2023-08-24T09:12:27.693644Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# sample_dir = \"medium_sample.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.731669Z","iopub.execute_input":"2023-08-24T09:12:27.732540Z","iopub.status.idle":"2023-08-24T09:12:27.736761Z","shell.execute_reply.started":"2023-08-24T09:12:27.732504Z","shell.execute_reply":"2023-08-24T09:12:27.735703Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# df_sample.to_csv(sample_dir)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.742300Z","iopub.execute_input":"2023-08-24T09:12:27.742603Z","iopub.status.idle":"2023-08-24T09:12:27.747608Z","shell.execute_reply.started":"2023-08-24T09:12:27.742578Z","shell.execute_reply":"2023-08-24T09:12:27.746592Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n\n# FileLink('medium_sample.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.774603Z","iopub.execute_input":"2023-08-24T09:12:27.776680Z","iopub.status.idle":"2023-08-24T09:12:27.780417Z","shell.execute_reply.started":"2023-08-24T09:12:27.776654Z","shell.execute_reply":"2023-08-24T09:12:27.779342Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n\nurl = \"https://drive.google.com/uc?id=1Nmu_Mq1tycGt9KUKvzsQTGoEr7007I96\"\nsample_dir = \"medium_sample.csv\"\ngdown.download(url, \"medium_sample.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:27.852424Z","iopub.execute_input":"2023-08-24T09:12:27.852721Z","iopub.status.idle":"2023-08-24T09:12:32.157917Z","shell.execute_reply.started":"2023-08-24T09:12:27.852695Z","shell.execute_reply":"2023-08-24T09:12:32.156829Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (uriginal): https://drive.google.com/uc?id=1Nmu_Mq1tycGt9KUKvzsQTGoEr7007I96\nFrom (redirected): https://drive.google.com/uc?id=1Nmu_Mq1tycGt9KUKvzsQTGoEr7007I96&confirm=t&uuid=c3de9425-1fc5-441d-afd6-c6a869c8cf2d\nTo: /kaggle/working/medium_sample.csv\n100%|██████████| 271M/271M [00:03<00:00, 78.1MB/s] \n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'medium_sample.csv'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"gpt2\"\n# data_path = \"/content/drive/MyDrive/data/medium_articles_cleaned.csv\"\noutput_dir = \"model_gpt2\"","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:32.160138Z","iopub.execute_input":"2023-08-24T09:12:32.160773Z","iopub.status.idle":"2023-08-24T09:12:32.165291Z","shell.execute_reply.started":"2023-08-24T09:12:32.160736Z","shell.execute_reply":"2023-08-24T09:12:32.164088Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\n\ntokenizer = GPT2Tokenizer.from_pretrained(\n    model_name,\n    bos_token=\"<|startoftext|>\",\n    eos_token=\"<|endoftext|>\",\n    pad_token=\"<|pad|>\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:32.167233Z","iopub.execute_input":"2023-08-24T09:12:32.167601Z","iopub.status.idle":"2023-08-24T09:12:35.134824Z","shell.execute_reply.started":"2023-08-24T09:12:32.167568Z","shell.execute_reply":"2023-08-24T09:12:35.133845Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07be5edfce674a5981dd0416fac85256"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1490de859be9485cba9149527ccd4583"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c23bf7c7f87b4308b513bd67b1829d20"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\nprint(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\nprint(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\nprint(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:35.138003Z","iopub.execute_input":"2023-08-24T09:12:35.138625Z","iopub.status.idle":"2023-08-24T09:12:35.146546Z","shell.execute_reply.started":"2023-08-24T09:12:35.138595Z","shell.execute_reply":"2023-08-24T09:12:35.145319Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\nThe beginning of sequence token <|startoftext|> token has the id 50257\nThe end of sequence token <|endoftext|> has the id 50256\nThe padding token <|pad|> has the id 50258\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata_files = {}\ndataset_args = {}\nvalidation_per = 5\ndata_files = {\n    \"train\": sample_dir\n}\n\nraw_datasets = load_dataset(\n    'csv',\n    sep=',',\n    data_files=data_files\n)\n\nraw_datasets['validation'] = load_dataset(\n    'csv',\n    sep=',',\n    data_files=data_files,\n    split=f\"train[:{validation_per}%]\",\n    **dataset_args\n)\n\nraw_datasets['train'] = load_dataset(\n    'csv',\n    sep=',',\n    data_files=data_files,\n    split=f\"train[{validation_per}%:]\",\n    **dataset_args\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:35.147910Z","iopub.execute_input":"2023-08-24T09:12:35.148922Z","iopub.status.idle":"2023-08-24T09:12:42.073180Z","shell.execute_reply.started":"2023-08-24T09:12:35.148883Z","shell.execute_reply":"2023-08-24T09:12:42.072188Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-434e0e10b1eac58b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f8faecf6aec4f3dbb8745c5929dce49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4036ac4a6fb4067a6eeaabd13370112"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-434e0e10b1eac58b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"763cb0f342d04486a0a56726d5daee12"}},"metadata":{}}]},{"cell_type":"code","source":"text_column_name = \"text\"\ncolumn_names = raw_datasets['train'].column_names \n\npreprocessing_num_workers = 3\n\ndef tokenize_function(examples):\n  output = tokenizer(examples[text_column_name], truncation=True)\n  return output\n\ntokenized_datasets = raw_datasets.map(\n    tokenize_function,\n    batched=True,\n    num_proc=preprocessing_num_workers,\n    remove_columns=column_names,\n    desc=\"Running tokenizer on dataset\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:12:42.074984Z","iopub.execute_input":"2023-08-24T09:12:42.075770Z","iopub.status.idle":"2023-08-24T09:19:44.892546Z","shell.execute_reply.started":"2023-08-24T09:12:42.075728Z","shell.execute_reply":"2023-08-24T09:19:44.889952Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset #0:   0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6bb0fd6af44003ba41d4efa23b856b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset #1:   0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72383e508adb4c6a8352ddba7cfa8272"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset #2:   0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95db4552f81b466c91afb6677eb47564"}},"metadata":{}},{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7987f28555746c8bc77dc8b205ba0e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1fd4405daab41ab94e90af3737d63d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebc11aae123341709136a97db963ce04"}},"metadata":{}}]},{"cell_type":"code","source":"from itertools import chain\n\nblock_size = 512\n\noverwrite_cache = False\n\ndef group_texts(examples):\n  concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n  total_length = len(concatenated_examples[list(examples.keys())[0]])\n\n  if total_length >= block_size:\n    total_length = (total_length // block_size) * block_size\n\n  result = {\n      k: [t[i:i+block_size] for i in range(0, total_length, block_size)] \n      for k, t in concatenated_examples.items()\n  }\n  result['labels'] = result['input_ids'].copy()\n  return result","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:19:44.895612Z","iopub.execute_input":"2023-08-24T09:19:44.896315Z","iopub.status.idle":"2023-08-24T09:19:44.905104Z","shell.execute_reply.started":"2023-08-24T09:19:44.896267Z","shell.execute_reply":"2023-08-24T09:19:44.903608Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"lm_datasets = tokenized_datasets.map(\n    group_texts,\n    batched=True,\n    num_proc=preprocessing_num_workers,\n    load_from_cache_file=not overwrite_cache,\n    desc=f\"Grouping texts in chunks of {block_size}\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:19:44.906524Z","iopub.execute_input":"2023-08-24T09:19:44.907496Z","iopub.status.idle":"2023-08-24T09:20:43.448590Z","shell.execute_reply.started":"2023-08-24T09:19:44.907459Z","shell.execute_reply":"2023-08-24T09:20:43.447316Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Grouping texts in chunks of 512 #0:   0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d619e929b584e4ba43922913708ff8b"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Grouping texts in chunks of 512 #2:   0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79cb1bd03c214251b87e21a99ce40ec3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Grouping texts in chunks of 512 #1:   0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5de6b66f6c834078953ca6235118a830"}},"metadata":{}},{"name":"stdout","text":"      ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Grouping texts in chunks of 512 #0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f50dd6aa92b4fcb88910a060f8433bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Grouping texts in chunks of 512 #2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"018bb015c9df40b998d8dc291f30011c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Grouping texts in chunks of 512 #1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca90741166d5432b89343af5f03a0ca3"}},"metadata":{}}]},{"cell_type":"code","source":"import torch \nimport random\nimport numpy as np\n\nfrom transformers import GPT2Config, GPT2LMHeadModel\n\n\nconfiguration = GPT2Config.from_pretrained(\n    model_name,\n    output_hidden_states=False\n)\n\nmodel = GPT2LMHeadModel.from_pretrained(\n    model_name,\n    config=configuration\n)\n\nmodel.resize_token_embeddings(len(tokenizer))\n\ndevice = \"cuda\"\nmodel.cuda()\n\n\nseed_val = 42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:20:43.451340Z","iopub.execute_input":"2023-08-24T09:20:43.451686Z","iopub.status.idle":"2023-08-24T09:21:08.974683Z","shell.execute_reply.started":"2023-08-24T09:20:43.451654Z","shell.execute_reply":"2023-08-24T09:21:08.973556Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"397d76b0c3df440da5c2fdf47d370c7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f5e0cf65d6e4bd1a55eec0a52838caa"}},"metadata":{}}]},{"cell_type":"code","source":"# model = torch.nn.parallel.DistributedDataParallel(model)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:21:08.978165Z","iopub.execute_input":"2023-08-24T09:21:08.978547Z","iopub.status.idle":"2023-08-24T09:21:08.985132Z","shell.execute_reply.started":"2023-08-24T09:21:08.978511Z","shell.execute_reply":"2023-08-24T09:21:08.984060Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from transformers import (\n    TrainingArguments,\n    Trainer,\n    default_data_collator\n)\n\ntrain_dataset = lm_datasets['train']\neval_dataset = lm_datasets['validation']\n\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    overwrite_output_dir=True,\n    evaluation_strategy=\"no\",\n    save_strategy=\"no\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=tokenizer,\n    data_collator=default_data_collator,\n    compute_metrics=None,\n    preprocess_logits_for_metrics=None,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:21:08.986564Z","iopub.execute_input":"2023-08-24T09:21:08.987160Z","iopub.status.idle":"2023-08-24T09:21:09.440136Z","shell.execute_reply.started":"2023-08-24T09:21:08.987124Z","shell.execute_reply":"2023-08-24T09:21:09.439088Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"train_result = trainer.train(resume_from_checkpoint=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T09:21:09.441787Z","iopub.execute_input":"2023-08-24T09:21:09.442174Z","iopub.status.idle":"2023-08-24T15:15:25.476970Z","shell.execute_reply.started":"2023-08-24T09:21:09.442135Z","shell.execute_reply":"2023-08-24T15:15:25.475780Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670731699999428, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"886108cf7ca04c4195ce9d80bca02177"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230824_093856-xovmfytg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/s-subodh7976/huggingface/runs/xovmfytg' target=\"_blank\">grateful-shadow-10</a></strong> to <a href='https://wandb.ai/s-subodh7976/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/s-subodh7976/huggingface' target=\"_blank\">https://wandb.ai/s-subodh7976/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/s-subodh7976/huggingface/runs/xovmfytg' target=\"_blank\">https://wandb.ai/s-subodh7976/huggingface/runs/xovmfytg</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13119' max='13119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13119/13119 5:35:48, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>3.867900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.221200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.193700</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.182900</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>3.167100</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.167100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>3.156800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>3.153400</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>3.139300</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>3.103200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>3.109800</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>3.104100</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>3.096900</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>3.100500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>3.095300</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>3.097400</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>3.097300</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>3.073100</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>3.061500</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>3.065700</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>3.068300</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>3.057000</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>3.064600</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>3.065200</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>3.055400</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>3.066600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Saving model to %s\" % output_dir)\n\ntrainer.save_model(output_dir=output_dir)\nmetrics = train_result.metrics\ntrainer.save_metrics(\"train\", metrics)\ntrainer.save_state()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T15:15:25.481854Z","iopub.execute_input":"2023-08-24T15:15:25.486995Z","iopub.status.idle":"2023-08-24T15:15:26.441140Z","shell.execute_reply.started":"2023-08-24T15:15:25.486947Z","shell.execute_reply":"2023-08-24T15:15:26.439946Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Saving model to model_gpt2\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r model.zip /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-08-24T15:16:15.666327Z","iopub.execute_input":"2023-08-24T15:16:15.666706Z","iopub.status.idle":"2023-08-24T15:17:03.691594Z","shell.execute_reply.started":"2023-08-24T15:16:15.666671Z","shell.execute_reply":"2023-08-24T15:17:03.689977Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"updating: kaggle/working/ (stored 0%)\nupdating: kaggle/working/model_gpt2/ (stored 0%)\nupdating: kaggle/working/model_gpt2/training_args.bin (deflated 49%)\nupdating: kaggle/working/model_gpt2/added_tokens.json (deflated 20%)\nupdating: kaggle/working/model_gpt2/special_tokens_map.json (deflated 78%)\nupdating: kaggle/working/model_gpt2/runs/ (stored 0%)\nupdating: kaggle/working/model_gpt2/runs/Aug24_09-21-09_472164ef4c83/ (stored 0%)\nupdating: kaggle/working/model_gpt2/runs/Aug24_09-21-09_472164ef4c83/events.out.tfevents.1692868869.472164ef4c83.28.0 (deflated 61%)\nupdating: kaggle/working/model_gpt2/all_results.json (deflated 37%)\nupdating: kaggle/working/model_gpt2/config.json (deflated 51%)\nupdating: kaggle/working/model_gpt2/vocab.json (deflated 68%)\nupdating: kaggle/working/model_gpt2/generation_config.json (deflated 24%)\nupdating: kaggle/working/model_gpt2/train_results.json (deflated 37%)\nupdating: kaggle/working/model_gpt2/merges.txt (deflated 53%)\nupdating: kaggle/working/model_gpt2/pytorch_model.bin (deflated 7%)\nupdating: kaggle/working/model_gpt2/tokenizer_config.json (deflated 74%)\nupdating: kaggle/working/model_gpt2/trainer_state.json (deflated 76%)\nupdating: kaggle/working/.virtual_documents/ (stored 0%)\nupdating: kaggle/working/wandb/ (stored 0%)\nupdating: kaggle/working/wandb/latest-run/ (stored 0%)\nupdating: kaggle/working/wandb/latest-run/tmp/ (stored 0%)\nupdating: kaggle/working/wandb/latest-run/tmp/code/ (stored 0%)\nupdating: kaggle/working/wandb/latest-run/logs/ (stored 0%)\nupdating: kaggle/working/wandb/latest-run/logs/debug.log (deflated 69%)\nupdating: kaggle/working/wandb/latest-run/logs/debug-internal.log (deflated 94%)\nupdating: kaggle/working/wandb/latest-run/files/ (stored 0%)\nupdating: kaggle/working/wandb/latest-run/files/config.yaml (deflated 76%)\nupdating: kaggle/working/wandb/latest-run/files/requirements.txt (deflated 58%)\nupdating: kaggle/working/wandb/latest-run/files/output.log (deflated 84%)\nupdating: kaggle/working/wandb/latest-run/files/conda-environment.yaml (deflated 66%)\nupdating: kaggle/working/wandb/latest-run/files/wandb-metadata.json (deflated 62%)\nupdating: kaggle/working/wandb/latest-run/files/wandb-summary.json (deflated 46%)\nupdating: kaggle/working/wandb/latest-run/run-xovmfytg.wandb (deflated 85%)\nupdating: kaggle/working/wandb/debug.log (deflated 69%)\nupdating: kaggle/working/wandb/debug-internal.log (deflated 94%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/ (stored 0%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/tmp/ (stored 0%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/tmp/code/ (stored 0%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/logs/ (stored 0%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/logs/debug.log (deflated 69%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/logs/debug-internal.log (deflated 94%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/files/ (stored 0%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/files/config.yaml (deflated 76%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/files/requirements.txt (deflated 58%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/files/output.log (deflated 84%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/files/conda-environment.yaml (deflated 66%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/files/wandb-metadata.json (deflated 62%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/files/wandb-summary.json (deflated 46%)\nupdating: kaggle/working/wandb/run-20230824_093856-xovmfytg/run-xovmfytg.wandb (deflated 85%)\nupdating: kaggle/working/medium_sample.csv (deflated 63%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('model.zip')","metadata":{"execution":{"iopub.status.busy":"2023-08-24T15:17:03.696583Z","iopub.execute_input":"2023-08-24T15:17:03.697378Z","iopub.status.idle":"2023-08-24T15:17:03.713578Z","shell.execute_reply.started":"2023-08-24T15:17:03.697330Z","shell.execute_reply":"2023-08-24T15:17:03.712582Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model.zip","text/html":"<a href='model.zip' target='_blank'>model.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"kwargs = {\n    \"finetuned_from\": model_name,\n    \"tasks\": \"text-generation\"\n}\ntrainer.create_model_card(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T15:17:47.660727Z","iopub.execute_input":"2023-08-24T15:17:47.661147Z","iopub.status.idle":"2023-08-24T15:17:48.062314Z","shell.execute_reply.started":"2023-08-24T15:17:47.661112Z","shell.execute_reply":"2023-08-24T15:17:48.061129Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nprompt = \"Write an essay on Title: Future in ai with tags: 'Artificial Intelligence', 'Mental Health'\"\n\ngenerated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\ngenerated = generated.to(torch.device(\"cuda\"))\n\nprint(generated)\n\nsample_outputs = model.generate(\n    generated,\n    do_sample=True,\n    top_k=50,\n    max_length=500,\n    top_p=0.95,\n    num_return_sequences=5\n)\n\nfor i, sample_output in enumerate(sample_outputs):\n  print(\"{}: {}\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))","metadata":{"execution":{"iopub.status.busy":"2023-08-24T15:35:48.771014Z","iopub.execute_input":"2023-08-24T15:35:48.771999Z","iopub.status.idle":"2023-08-24T15:35:58.126970Z","shell.execute_reply.started":"2023-08-24T15:35:48.771958Z","shell.execute_reply":"2023-08-24T15:35:58.125966Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"tensor([[16594,   281, 14268,   319, 11851,    25, 10898,   287,   257,    72,\n           351, 15940,    25,   705,  8001,  9542,  9345,  3256,   705,    44,\n          2470,  3893,     6]], device='cuda:0')\n0: Write an essay on Title: Future in ai with tags: 'Artificial Intelligence', 'Mental Health', Future, Futureproof, Software \nArticle Text:  Ai is the future in ai for i and k users, not only that in its current state, but it has matured from the past and has achieved the ability to analyze data, analyse data, measure data, and even interact with data.\n\nAccording to many research studies, Ai is evolving from being only a tool that is used in ai to being a tool that can be used for different domains. In this post, I will explain the main reasons behind this thinking, how AI and AI-led technologies are impacting our lives, in the hopes of enhancing our knowledge and saving lives.\n\nThe aim is to show how data can help us think beyond traditional thinking, and how people are able to develop knowledge and improve their understanding. So you are probably thinking that AI is the future and that AI-led technologies will revolutionise society.\n\nHowever, this is not the case.\n\nToday, data is often the first thing of a person’s mind that helps them think through the situation and what may have happened. Today, we will discuss the reasons why these technologies are impacting the lives of our everyday.\n\nAi is becoming an indispensable tool in AI-enabled scenarios\n\nAaificial Intelligence is becoming one of the most important components in AI-led technologies, because it is bringing about the development of new algorithms and algorithms in computer and the internet era. Currently, the majority of people are working in AI-enabled fields, including healthcare and education. AI has given us the power to analyze data and measure data. With all the technologies used to analyze data, AI-led technologies will revolutionise healthcare and education in the future, which will be of greater importance if the demand for AI-led technologies increases.\n\nAI-led technologies are using the internet to help doctors, hospitals, teachers and others to better understand patients and also help in dealing with health problems. These technologies provide the potential to automate data to increase the number of doctors, hospitals, educators and doctors.\n\nThe advent of AI-led technology is also transforming the lives of millions of people. The number of AI-led people is now more than 8 billion, but also more than 7 billion people across the globe. The growth of AI-enabled technologies is also driving a huge\n\n1: Write an essay on Title: Future in ai with tags: 'Artificial Intelligence', 'Mental Health' \nArticle Text:  Photo by Ryan Lutz on Unsplash\n\nIn an upcoming article, I will take a look at what technology can do to improve mental health, and then examine whether we can get to a stage where AI can do that for you. So I’ll give some background to what ai will entail and then hopefully show what ai can bring you.\n\nBefore the jump, we know what it is we’re doing in this article.\n\nWhat is ai, a term coined by the author of the book and most known for its scientific applications in mental health care.\n\nWhat is ai?\n\nAi is a brain-computer interface, commonly referred to as ai-bridge. A i-bridge connects neurons of the brain to each other. Each neuron of your brain will have its own unique interface.\n\nIn the world of computerization, the more a machine communicates with you in real time, the more sophisticated the information it is able to carry out. To achieve this, most of the world has now integrated the i-bridge into its human interfaces.\n\nWhy is AI so important?\n\nResearch has shown that people who are better at language and communication are significantly more likely to experience mental health problems than those who are more experienced at language and communication.\n\n“We used to be able to understand something like, ‘oh it’s been five hours for the last ten minutes, it’s been an hour, let’s just say, fifteen minutes ago.” — Bill Gates\n\nA computer might not be able to take that long for you.\n\nHowever, that does not mean the time will be too short. As a result, these two areas will have a similar impact on mental health.\n\n“The problem, in addition to being less complicated to understand, is that you will also be able to learn more quickly” — William Houde, professor of psychology at the University of Michigan\n\nIt’s likely that AI will create more problems than its human counterparts for mental health, even though we’ve already been there.\n\nFor example, what happened in the late 1990’s with Alzheimer’s disease?\n\nAt this time, most people\n\n2: Write an essay on Title: Future in ai with tags: 'Artificial Intelligence', 'Mental Health' \nArticle Text:  This is not a new term but a new one. From the perspective of AI it is all about Artificial Intelligence and how they affect our human mental health. But when it comes to technology we are just waiting for AI to revolutionize the way we behave.\n\nWhile the news that I have been writing about AI lately has a lot to do with how the pandemic has affected us, there has been no shortage of articles and blogs about Artificial Intelligence since its arrival in this world. In fact, when this is the year that AI has become the default option for all social and economic activities, I am almost certain it will be a topic of great interest to all social and economic activities.\n\nI am not gonna lie, there has been a lot of research in the past 3 months about AI that has not been very good at the moment. Here are a few thoughts and thoughts I have found and will be writing about them as well.\n\n1. Ai isn’t a solution\n\nAI technologies have gone through many iterations and are constantly evolving. It was only in the past 30 years that a large number of organizations, research institutes, and professionals were researching their solutions for AI. But I believe that the problem of AI is not a solved problem but an issue for the future.\n\nAI has been used to solve problems for many years but in recent times its progress is slow and it still can not solve a problem as fast as it used to. This is because there are no continuous systems and it is easier for AI to change and adapt its operations. This is not true for an organization as its management team could have to switch teams and go through several iterations to make it work smoothly and efficiently.\n\nIt is only a short period of time that most business analysts are dealing with AI because of this problem. But if you are a business analyst, it is easy for you to forget the AI issues and forget about the problems. This is why ai is considered as a technology as opposed to a business solution.\n\n2. Ai isn’t a solution for COVID-19\n\nSome have pointed to AI as a solution for COVID-19 and others have said that ai will provide a solution only for the COVID-19 crisis. As a result, this is very\n\n3: Write an essay on Title: Future in ai with tags: 'Artificial Intelligence', 'Mental Health'with tags: Medical, AI, AI Future, Medical Technology \nArticle Text:  AI is entering every field. For every category in science and medicine, there is a different path available to the AI world. That’s where the next generation of AI will be coming into focus. According to one prominent expert, AI is going to change society in a big way. This is the first step towards bringing AI into the world of medicine.\n\nIt is likely that AI will take over many professions.\n\nPhoto by Michael Grosman on Unsplash\n\nWhat makes AI different from the typical other fields are its potential for self-improvement.\n\nTo understand AI better I need to understand what it means and how it impacts the health industry.\n\nThe first thing we have to understand is the impact on the health industry.\n\nIf a person can’t get the correct help right from the doctors, and then they need to rely on expensive drugs to save their lives, then there is no doubt that AI will take a hit.\n\nSo how do we deal with the impact of AI in medicine?\n\nIn this article, I will tell you about three major areas of AI impacting the medicine industry.\n\n1. The impact on patients.\n\nThe impact of AI in medicine will be the same as the impact of other fields.\n\nIf a person can only get help from doctors and medical clinics, but not from anyone else, then there is a significant danger that patients won’t get the proper support.\n\nThis means that they will suffer greatly.\n\nIf there is too much pain in your body, you will have a much higher chance of getting sick than if there is not enough pain in your mind, or in the brain, which causes you to have a higher chance of dying.\n\nIf there is too much stress, you will get stressed.\n\nIf there is too much stress, you will develop chronic pain which leads to pain in your legs, arms and lower back.\n\nIf there is too much stress, your brain will be overloaded and stop functioning properly.\n\nIf there is too much stress, you will develop dementia which leads to long-term blindness.\n\nThis is the last point that we want to cover.\n\n2. The\n\n4: Write an essay on Title: Future in ai with tags: 'Artificial Intelligence', 'Mental Health' \nArticle Text:  Future in ai with tags: Future, Artificial Intelligence, Future Goals, Future Of Life \nArticle Text:  Future in ai with tags: Future, Future Goals, Future Of Life, Future Of Life Science \nArticle Text:  Future in ai with tags: Future, Future, AI, AI Technology \nThe main aim of the article is to show that a future in ai technology will enable the future to be more accessible for human beings to engage and learn. This is an amazing result.\n\nIn this article, I will focus on one of the major problems of human mind when it comes to the human mind: the cognitive and motor ability, and thus the speed at which these abilities can be acquired, enhanced and maintained.\n\nThe aim of this article is to give a basic idea about how a technology will be able to solve this problem, and how it will impact people’s lives and how it will drive the future forward.\n\nBefore discussing ai technology, let us discuss a very simple, but important concept of the future in ai.\n\nThe future is in a constant state of being in the form of a complete, uninterrupted, universal, infinite universe, and there are only two possible forms: the human and the machine.\n\nSo far, humanity has managed to create a complete world by its very nature, so how does it want to continue in the present situation?\n\nThe following section will provide us with the simplest possible form.\n\n1. The Universal Turing Machine\n\nThe Turing Machine is a kind of computer that is capable of doing everything the human brain cannot do. Turing created the Turing machine as a tool of human intelligence. The Turing Machine can only do “something”, because it cannot answer questions. The Turing Machine is also very efficient for its computation and therefore it is able to solve many kinds of problems.\n\nThe problem\n\nWhat is the solution to this problem? How can it be achieved?\n\nThe answer to the problem is to create an artificial intelligence system that can perform tasks that a human brain cannot. The technology can also perform tasks that a human brain cannot do. To get an AI system, we need to have the ability to do what a human brain can not do (read: use speech,\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --quiet pickle","metadata":{"execution":{"iopub.status.busy":"2023-08-24T15:19:07.244310Z","iopub.execute_input":"2023-08-24T15:19:07.245388Z","iopub.status.idle":"2023-08-24T15:19:09.388609Z","shell.execute_reply.started":"2023-08-24T15:19:07.245337Z","shell.execute_reply":"2023-08-24T15:19:09.387122Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"output_dir = \"model_gpt2\"\nmodel = GPT2LMHeadModel.from_pretrained(output_dir)\ntokenizer = GPT2Tokenizer.from_pretrained(output_dir)\nmodel.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2023-08-24T15:19:47.721452Z","iopub.execute_input":"2023-08-24T15:19:47.721880Z","iopub.status.idle":"2023-08-24T15:19:50.123694Z","shell.execute_reply.started":"2023-08-24T15:19:47.721842Z","shell.execute_reply":"2023-08-24T15:19:50.122556Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50259, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}